{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports, as always...\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import ast\n",
    "\n",
    "import create_data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautification.\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_style({'font.family':'serif', 'font.serif':'Times New Roman'})\n",
    "sns.set_context('paper')\n",
    "sns.set_palette('Set2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-existing master data file found (no new data created).\n"
     ]
    }
   ],
   "source": [
    "# Create master data for Edinburgh (if not created already).\n",
    "if not Path('datasets/master_edinburgh.csv').is_file():\n",
    "    create_data.city_data_generation('edinburgh', 'datasets', datetime(2022, 12, 16), True)\n",
    "    print('Master data file generated.')\n",
    "\n",
    "else:\n",
    "    print('Pre-existing master data file found (no new data created).')\n",
    "\n",
    "# Note: This takes around 3 minutes on my laptop for ~7500 listings and ~500000 reviews (Edinburgh).\n",
    "\n",
    "# Get the master data.\n",
    "master_data = pd.read_csv('datasets/master_edinburgh.csv').iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features used in success score definition.\n",
    "master_data.drop(columns=[\n",
    "    #'price',\n",
    "    'minimum_nights_avg_ntm',\n",
    "    'number_of_reviews_ltm', \n",
    "    'review_scores_rating'\n",
    "], inplace=True, axis=1)\n",
    "\n",
    "# It would also be in the spirit of things to remove other review scores (e.g. for cleanliness), as that is sort of cheating.\n",
    "master_data.drop(columns=[\n",
    "    'review_scores_accuracy', \n",
    "    'review_scores_cleanliness',\n",
    "    'review_scores_checkin', \n",
    "    'review_scores_communication',\n",
    "    'review_scores_location', \n",
    "    'review_scores_value'\n",
    "], inplace=True, axis=1)\n",
    "\n",
    "# Drop unhelpful features.\n",
    "master_data.drop(columns=[\n",
    "    'calculated_host_listings_count_shared_rooms',\n",
    "    'neighbourhood',\n",
    "    'neighbourhood_cleansed',\n",
    "    'property_type',\n",
    "    'bathrooms_text',\n",
    "    'amenities',\n",
    "], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7389 entries, 0 to 7388\n",
      "Data columns (total 67 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            7389 non-null   int64  \n",
      " 1   host_id                                       7389 non-null   int64  \n",
      " 2   host_since                                    7389 non-null   object \n",
      " 3   host_response_time                            5861 non-null   object \n",
      " 4   host_response_rate                            5861 non-null   object \n",
      " 5   host_acceptance_rate                          6663 non-null   object \n",
      " 6   host_is_superhost                             7387 non-null   object \n",
      " 7   host_neighbourhood                            3007 non-null   object \n",
      " 8   host_listings_count                           7389 non-null   int64  \n",
      " 9   host_total_listings_count                     7389 non-null   int64  \n",
      " 10  host_verifications                            7389 non-null   object \n",
      " 11  host_has_profile_pic                          7389 non-null   object \n",
      " 12  host_identity_verified                        7389 non-null   object \n",
      " 13  neighbourhood_group_cleansed                  0 non-null      float64\n",
      " 14  latitude                                      7389 non-null   float64\n",
      " 15  longitude                                     7389 non-null   float64\n",
      " 16  room_type                                     7389 non-null   object \n",
      " 17  accommodates                                  7389 non-null   int64  \n",
      " 18  bathrooms                                     0 non-null      float64\n",
      " 19  bedrooms                                      7251 non-null   float64\n",
      " 20  beds                                          7284 non-null   float64\n",
      " 21  price                                         7389 non-null   object \n",
      " 22  minimum_nights                                7389 non-null   int64  \n",
      " 23  maximum_nights                                7389 non-null   int64  \n",
      " 24  minimum_minimum_nights                        7389 non-null   int64  \n",
      " 25  maximum_minimum_nights                        7389 non-null   int64  \n",
      " 26  minimum_maximum_nights                        7389 non-null   int64  \n",
      " 27  maximum_maximum_nights                        7389 non-null   int64  \n",
      " 28  maximum_nights_avg_ntm                        7389 non-null   float64\n",
      " 29  has_availability                              7389 non-null   object \n",
      " 30  availability_30                               7389 non-null   int64  \n",
      " 31  availability_60                               7389 non-null   int64  \n",
      " 32  availability_90                               7389 non-null   int64  \n",
      " 33  availability_365                              7389 non-null   int64  \n",
      " 34  number_of_reviews                             7389 non-null   int64  \n",
      " 35  number_of_reviews_l30d                        7389 non-null   int64  \n",
      " 36  first_review                                  6724 non-null   object \n",
      " 37  last_review                                   6724 non-null   object \n",
      " 38  license                                       15 non-null     object \n",
      " 39  instant_bookable                              7389 non-null   object \n",
      " 40  calculated_host_listings_count                7389 non-null   int64  \n",
      " 41  calculated_host_listings_count_entire_homes   7389 non-null   int64  \n",
      " 42  calculated_host_listings_count_private_rooms  7389 non-null   int64  \n",
      " 43  reviews_per_month                             6724 non-null   float64\n",
      " 44  title_neg                                     7389 non-null   float64\n",
      " 45  title_neu                                     7389 non-null   float64\n",
      " 46  title_pos                                     7389 non-null   float64\n",
      " 47  title_compound                                7389 non-null   float64\n",
      " 48  description_neg                               7389 non-null   float64\n",
      " 49  description_neu                               7389 non-null   float64\n",
      " 50  description_pos                               7389 non-null   float64\n",
      " 51  description_compound                          7389 non-null   float64\n",
      " 52  neighborhood_overview_neg                     7389 non-null   float64\n",
      " 53  neighborhood_overview_neu                     7389 non-null   float64\n",
      " 54  neighborhood_overview_pos                     7389 non-null   float64\n",
      " 55  neighborhood_overview_compound                7389 non-null   float64\n",
      " 56  host_about_neg                                7389 non-null   float64\n",
      " 57  host_about_neu                                7389 non-null   float64\n",
      " 58  host_about_pos                                7389 non-null   float64\n",
      " 59  host_about_compound                           7389 non-null   float64\n",
      " 60  perceived_review_neg                          6723 non-null   float64\n",
      " 61  perceived_review_neu                          6723 non-null   float64\n",
      " 62  perceived_review_pos                          6723 non-null   float64\n",
      " 63  perceived_review_compound                     6723 non-null   float64\n",
      " 64  images_keywords                               5126 non-null   object \n",
      " 65  images_confidences                            5126 non-null   object \n",
      " 66  success_score                                 6720 non-null   float64\n",
      "dtypes: float64(29), int64(20), object(18)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "master_data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for converting dates to days since.\n",
    "def elapsed_days(from_date_as_string, to_date=datetime(2022, 12, 16)):\n",
    "    from_date = datetime.strptime(from_date_as_string, '%Y-%m-%d')\n",
    "    return max(0, (to_date - from_date).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pseudonumeric types (e.g. dates) to numeric...\n",
    "\n",
    "master_data.host_since = master_data.host_since.apply(elapsed_days)\n",
    "\n",
    "master_data.price = master_data.price.apply(\n",
    "    lambda x : float(x.replace(',', '').replace('$', '')) if not pd.isna(x) \n",
    "    else x\n",
    ")\n",
    "\n",
    "master_data.host_response_rate = master_data.host_response_rate.apply(\n",
    "    lambda x : float(x[:-1]) if not pd.isna(x) \n",
    "    else x\n",
    ")\n",
    "\n",
    "master_data.host_acceptance_rate = master_data.host_acceptance_rate.apply(\n",
    "    lambda x : float(x[:-1]) if not pd.isna(x) \n",
    "    else x\n",
    ")\n",
    "\n",
    "master_data.host_verifications = master_data.host_verifications.apply(\n",
    "    lambda x : len(x)\n",
    ")\n",
    "\n",
    "master_data.first_review = master_data.first_review.apply(\n",
    "    lambda x : elapsed_days(x) if not pd.isna(x)\n",
    "    else x\n",
    ")\n",
    "\n",
    "master_data.last_review = master_data.last_review.apply(\n",
    "    lambda x : elapsed_days(x) if not pd.isna(x)\n",
    "    else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical (e.g. boolean) types to numeric...\n",
    "\n",
    "master_data.host_response_time = master_data.host_response_time.map(\n",
    "    lambda x : {'within an hour' : 1, 'within a few hours' : 2, 'within a day' : 3, 'a few days or more' : 4}.get(x, 0)\n",
    ")\n",
    "\n",
    "master_data.host_is_superhost = master_data.host_is_superhost.map(\n",
    "    lambda x : {'t' : 1, 'f' : 0}.get(x, 0)\n",
    ")\n",
    "\n",
    "master_data.host_identity_verified = master_data.host_identity_verified.map(\n",
    "    lambda x : {'t' : 1, 'f' : 0}.get(x, 0)\n",
    ")\n",
    "\n",
    "master_data.room_type = master_data.room_type.map(\n",
    "    lambda x : {'Entire home/apt' : 1, 'Private room' : 2, 'Hotel room' : 3, 'Shared room' : 4}.get(x, 0)\n",
    ")\n",
    "\n",
    "master_data.instant_bookable = master_data.instant_bookable.map(\n",
    "    lambda x : {'t' : 1, 'f' : 0}.get(x, 0)\n",
    ")\n",
    "\n",
    "master_data.host_has_profile_pic = master_data.host_has_profile_pic.map(\n",
    "    lambda x : {'t' : 1, 'f' : 0}.get(x, 0)\n",
    ")\n",
    "\n",
    "master_data.has_availability = master_data.has_availability.map(\n",
    "    lambda x : {'t' : 1, 'f' : 0}.get(x, 0)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped: Index(['bathrooms', 'neighbourhood_group_cleansed', 'license',\n",
      "       'host_neighbourhood'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Count the number of missing values in each feature.\n",
    "missing_values = master_data.isna().sum().sort_values(ascending=False)\n",
    "\n",
    "# Drop features with majority missing values.\n",
    "threshold = master_data.shape[0] // 2\n",
    "master_data.drop(columns=missing_values[missing_values > threshold].index, inplace=True, axis=1)\n",
    "print('dropped:', missing_values[missing_values > threshold].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dropped rows (no success score): 669\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing a succuess score.\n",
    "print('Number of dropped rows (no success score):', len(master_data[master_data.success_score.isna()]))\n",
    "master_data = master_data[master_data.success_score.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dropped rows (no image labels): 2091\n"
     ]
    }
   ],
   "source": [
    "# Drop rows missing image label extractions.\n",
    "print('Number of dropped rows (no image labels):', len(master_data[master_data.images_keywords.isna()]))\n",
    "master_data = master_data[master_data.images_keywords.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'host_id', 'host_since', 'host_response_time',\n",
       "       'host_response_rate', 'host_acceptance_rate', 'host_is_superhost',\n",
       "       'host_listings_count', 'host_total_listings_count',\n",
       "       'host_verifications', 'host_has_profile_pic', 'host_identity_verified',\n",
       "       'latitude', 'longitude', 'room_type', 'accommodates', 'bedrooms',\n",
       "       'beds', 'price', 'minimum_nights', 'maximum_nights',\n",
       "       'minimum_minimum_nights', 'maximum_minimum_nights',\n",
       "       'minimum_maximum_nights', 'maximum_maximum_nights',\n",
       "       'maximum_nights_avg_ntm', 'has_availability', 'availability_30',\n",
       "       'availability_60', 'availability_90', 'availability_365',\n",
       "       'number_of_reviews', 'number_of_reviews_l30d', 'first_review',\n",
       "       'last_review', 'instant_bookable', 'calculated_host_listings_count',\n",
       "       'calculated_host_listings_count_entire_homes',\n",
       "       'calculated_host_listings_count_private_rooms', 'reviews_per_month',\n",
       "       'title_neg', 'title_neu', 'title_pos', 'title_compound',\n",
       "       'description_neg', 'description_neu', 'description_pos',\n",
       "       'description_compound', 'neighborhood_overview_neg',\n",
       "       'neighborhood_overview_neu', 'neighborhood_overview_pos',\n",
       "       'neighborhood_overview_compound', 'host_about_neg', 'host_about_neu',\n",
       "       'host_about_pos', 'host_about_compound', 'perceived_review_neg',\n",
       "       'perceived_review_neu', 'perceived_review_pos',\n",
       "       'perceived_review_compound', 'images_keywords', 'images_confidences',\n",
       "       'success_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining data examples: 4629\n"
     ]
    }
   ],
   "source": [
    "# Replace missing sentiment analyses with 0 scores.\n",
    "master_data.title_neg = master_data.title_neg.fillna(0)\n",
    "master_data.title_neu = master_data.title_neu.fillna(0)\n",
    "master_data.title_pos = master_data.title_pos.fillna(0)\n",
    "master_data.title_compound = master_data.title_compound.fillna(0)\n",
    "master_data.description_neg = master_data.description_neg.fillna(0)\n",
    "master_data.description_neu = master_data.description_neu.fillna(0)\n",
    "master_data.description_pos = master_data.description_pos.fillna(0)\n",
    "master_data.description_compound = master_data.description_compound.fillna(0)\n",
    "master_data.neighborhood_overview_neg = master_data.neighborhood_overview_neg.fillna(0)\n",
    "master_data.neighborhood_overview_neu = master_data.neighborhood_overview_neu.fillna(0)\n",
    "master_data.neighborhood_overview_pos = master_data.neighborhood_overview_pos.fillna(0)\n",
    "master_data.neighborhood_overview_compound = master_data.neighborhood_overview_compound.fillna(0)\n",
    "master_data.host_about_neg = master_data.host_about_neg.fillna(0)\n",
    "master_data.host_about_neu = master_data.host_about_neu.fillna(0)\n",
    "master_data.host_about_pos = master_data.host_about_pos.fillna(0)\n",
    "master_data.host_about_compound = master_data.host_about_compound.fillna(0)\n",
    "master_data.perceived_review_neg = master_data.perceived_review_neg.fillna(0)\n",
    "master_data.perceived_review_neu = master_data.perceived_review_neu.fillna(0)\n",
    "master_data.perceived_review_pos = master_data.perceived_review_pos.fillna(0)\n",
    "master_data.perceived_review_compound = master_data.perceived_review_compound.fillna(0)\n",
    "\n",
    "# Replace missing host_response_rate, host_acceptance_rate with mean values.\n",
    "master_data.host_response_rate = master_data.host_response_rate.fillna(master_data.host_response_rate.mean())\n",
    "master_data.host_acceptance_rate = master_data.host_acceptance_rate.fillna(master_data.host_acceptance_rate.mean()) \n",
    "\n",
    "# Replace missing host_response_time with mode values.\n",
    "master_data.host_response_time = master_data.host_response_time.fillna(master_data.host_response_time.mode().values[0])\n",
    "\n",
    "# Replace missing bedroom and beds with mean values.\n",
    "master_data.bedrooms = master_data.bedrooms.fillna(master_data.bedrooms.mean())\n",
    "master_data.beds = master_data.beds.fillna(master_data.beds.mean())\n",
    "\n",
    "# Remove all remaining rows with missing values.\n",
    "master_data = master_data.dropna()\n",
    "\n",
    "print(\"Remaining data examples:\", len(master_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualte the success of the image keywords.\n",
    "keyword_success = create_data.mean_keyword_scores(master_data[['id', 'success_score']], 'datasets/image_keywords_edinburgh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each listing, compute the mean and standard deviation in the perceived success of image keywords.\n",
    "weighted_image_score_mean = []\n",
    "weighted_image_score_max = []\n",
    "weighted_image_score_min = []\n",
    "weighted_image_score_std = []\n",
    "\n",
    "for i in range(len(master_data.index)):\n",
    "    entry = master_data.iloc[i]\n",
    "\n",
    "    keywords = ast.literal_eval(entry.images_keywords)\n",
    "    confidences = ast.literal_eval(entry.images_confidences)\n",
    "\n",
    "    scores = []\n",
    "    for j in range(len(keywords)):\n",
    "        scores.append(keyword_success[keywords[j]] * (confidences[j] / 100)) \n",
    "\n",
    "    weighted_image_score_mean.append(np.mean(scores))\n",
    "    weighted_image_score_max.append(max(scores))\n",
    "    weighted_image_score_min.append(min(scores))\n",
    "    weighted_image_score_std.append(np.std(scores))\n",
    "\n",
    "master_data['weighted_image_score_mean'] = weighted_image_score_mean\n",
    "master_data['weighted_image_score_max'] = weighted_image_score_max\n",
    "master_data['weighted_image_score_min'] = weighted_image_score_min\n",
    "master_data['weighted_image_score_std'] = weighted_image_score_std"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final skewness...\n",
      "title_neg                         12.307575\n",
      "weighted_image_score_max           6.019608\n",
      "minimum_minimum_nights             3.039192\n",
      "minimum_nights                     2.963458\n",
      "host_about_neg                     2.685665\n",
      "maximum_minimum_nights             2.218628\n",
      "neighborhood_overview_neg          2.104362\n",
      "host_listings_count                1.780214\n",
      "host_total_listings_count          1.738642\n",
      "calculated_host_listings_count     1.639883\n",
      "longitude                          1.588900\n",
      "host_identity_verified            -2.619935\n",
      "host_has_profile_pic              -8.690194\n",
      "has_availability                 -33.985281\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Handle skewness (to a maximum point).\n",
    "max_handling_steps = 5\n",
    "\n",
    "for i in range(max_handling_steps):\n",
    "    # Calculate the skewness of the features.\n",
    "    skewness = master_data.skew().sort_values(ascending=False)\n",
    "\n",
    "    # Deal with positive skewness by performing a square root transformation.\n",
    "    for skew_feature in skewness[skewness > 1].index:\n",
    "        master_data[skew_feature] = np.power(master_data[skew_feature], 1/2)\n",
    "\n",
    "    # Deal with negative skewness by performing a square transformation.\n",
    "    for skew_feature in skewness[skewness < -1].index:\n",
    "        master_data[skew_feature] = np.power(master_data[skew_feature], 2)\n",
    "    \n",
    "print(\"Final skewness...\")\n",
    "skewness = master_data.skew().sort_values(ascending=False)\n",
    "print(skewness[abs(skewness) > 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create the scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalise the data\n",
    "data_to_normalise = master_data.drop(columns=['images_keywords', 'images_confidences'], axis=1)\n",
    "normalised_data = pd.DataFrame(scaler.fit_transform(data_to_normalise), columns=data_to_normalise.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining (normalised) data examples: 4629\n"
     ]
    }
   ],
   "source": [
    "# Remove introduded missing values (?).\n",
    "normalised_data = normalised_data.dropna()\n",
    "\n",
    "print(\"Remaining (normalised) data examples:\", len(normalised_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'host_id', 'host_since', 'host_response_time',\n",
       "       'host_response_rate', 'host_acceptance_rate', 'host_is_superhost',\n",
       "       'host_listings_count', 'host_total_listings_count',\n",
       "       'host_verifications', 'host_has_profile_pic', 'host_identity_verified',\n",
       "       'latitude', 'longitude', 'room_type', 'accommodates', 'bedrooms',\n",
       "       'beds', 'price', 'minimum_nights', 'maximum_nights',\n",
       "       'minimum_minimum_nights', 'maximum_minimum_nights',\n",
       "       'minimum_maximum_nights', 'maximum_maximum_nights',\n",
       "       'maximum_nights_avg_ntm', 'has_availability', 'availability_30',\n",
       "       'availability_60', 'availability_90', 'availability_365',\n",
       "       'number_of_reviews', 'number_of_reviews_l30d', 'first_review',\n",
       "       'last_review', 'instant_bookable', 'calculated_host_listings_count',\n",
       "       'calculated_host_listings_count_entire_homes',\n",
       "       'calculated_host_listings_count_private_rooms', 'reviews_per_month',\n",
       "       'title_neg', 'title_neu', 'title_pos', 'title_compound',\n",
       "       'description_neg', 'description_neu', 'description_pos',\n",
       "       'description_compound', 'neighborhood_overview_neg',\n",
       "       'neighborhood_overview_neu', 'neighborhood_overview_pos',\n",
       "       'neighborhood_overview_compound', 'host_about_neg', 'host_about_neu',\n",
       "       'host_about_pos', 'host_about_compound', 'perceived_review_neg',\n",
       "       'perceived_review_neu', 'perceived_review_pos',\n",
       "       'perceived_review_compound', 'success_score',\n",
       "       'weighted_image_score_mean', 'weighted_image_score_max',\n",
       "       'weighted_image_score_min', 'weighted_image_score_std'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create structured-only, unstructured-only, and hybrid datasets\n",
    "X_struct = normalised_data[[\n",
    "    'host_since', 'host_response_time',\n",
    "    'host_response_rate', 'host_acceptance_rate', 'host_is_superhost',\n",
    "    'host_listings_count', 'host_total_listings_count',\n",
    "    'host_verifications', 'host_has_profile_pic', 'host_identity_verified',\n",
    "    'latitude', 'longitude', 'room_type', 'accommodates', 'bedrooms',\n",
    "    'beds', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
    "    'maximum_minimum_nights', 'minimum_maximum_nights',\n",
    "    'maximum_maximum_nights', 'maximum_nights_avg_ntm', 'has_availability',\n",
    "    'availability_30', 'availability_60', 'availability_90',\n",
    "    'availability_365', 'number_of_reviews', 'number_of_reviews_l30d',\n",
    "    'first_review', 'last_review', 'instant_bookable',\n",
    "    'calculated_host_listings_count',\n",
    "    'calculated_host_listings_count_entire_homes',\n",
    "    'calculated_host_listings_count_private_rooms', 'reviews_per_month'\n",
    "]]\n",
    "\n",
    "X_unstruct = normalised_data[[\n",
    "    'title_neg', 'title_neu', 'title_pos', 'title_compound',\n",
    "    'description_neg', 'description_neu', 'description_pos',\n",
    "    'description_compound', 'neighborhood_overview_neg',\n",
    "    'neighborhood_overview_neu', 'neighborhood_overview_pos',\n",
    "    'neighborhood_overview_compound', 'host_about_neg', 'host_about_neu',\n",
    "    'host_about_pos', 'host_about_compound', 'perceived_review_neg',\n",
    "    'perceived_review_neu', 'perceived_review_pos',\n",
    "    'perceived_review_compound',\n",
    "    'weighted_image_score_mean', 'weighted_image_score_max',\n",
    "    'weighted_image_score_min', 'weighted_image_score_std'\n",
    "]]\n",
    "\n",
    "X_hybrid = normalised_data.drop(columns=['id', 'host_id', 'success_score', 'price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate succes scores from the rest of the data.\n",
    "# CHANGE THIS TO BE EITHER SUCCESS SCORE OR PRICE, DEPENDING ON WHAT YOU WANT.\n",
    "y = normalised_data.success_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct PCA on each dataset...\n",
    "\n",
    "# Reduce the dimensionality as much as possible while retaining some threshold variance explanation.\n",
    "threshold_explained_variance = 0.9\n",
    "\n",
    "struct_pca = PCA()\n",
    "X_struct_pca = struct_pca.fit_transform(X=X_struct, y=y)\n",
    "\n",
    "for i in range(len(struct_pca.components_)):\n",
    "    if sum(struct_pca.explained_variance_ratio_[:i]) > threshold_explained_variance:\n",
    "        break\n",
    "\n",
    "X_struct_pca = pd.DataFrame(X_struct_pca).iloc[:,:i]\n",
    "\n",
    "unstruct_pca = PCA()\n",
    "X_unstruct_pca = unstruct_pca.fit_transform(X=X_unstruct, y=y)\n",
    "\n",
    "\n",
    "for i in range(len(unstruct_pca.components_)):\n",
    "    if sum(unstruct_pca.explained_variance_ratio_[:i]) > threshold_explained_variance:\n",
    "        break\n",
    "\n",
    "X_unstruct_pca = pd.DataFrame(X_unstruct_pca).iloc[:,:i]\n",
    "\n",
    "hybrid_pca = PCA()\n",
    "X_hybrid_pca = hybrid_pca.fit_transform(X=X_hybrid, y=y)\n",
    "\n",
    "for i in range(len(hybrid_pca.components_)):\n",
    "    if sum(hybrid_pca.explained_variance_ratio_[:i]) > threshold_explained_variance:\n",
    "        break\n",
    "\n",
    "X_hybrid_pca = pd.DataFrame(X_hybrid_pca).iloc[:,:i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split for each dataset.\n",
    "X_struct_train, X_struct_test, y_struct_train, y_struct_test = train_test_split(X_struct_pca, y, test_size=0.2, random_state=47)\n",
    "X_unstruct_train, X_unstruct_test, y_unstruct_train, y_unstruct_test = train_test_split(X_unstruct_pca, y, test_size=0.2, random_state=47)\n",
    "X_hybrid_train, X_hybrid_test, y_hybrid_train, y_hybrid_test = train_test_split(X_hybrid_pca, y, test_size=0.2, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression...\n",
      "Structured: MAE = 0.00468, MSE = 0.04907, R2 Score = 0.41896\n",
      "Unstructured: MAE = 0.00794, MSE = 0.06546, R2 Score = 0.01284\n",
      "Hybrid: MAE = 0.00421, MSE = 0.04533, R2 Score = 0.47628\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression...\n",
    "lin_reg_struct = LinearRegression().fit(X_struct_train, y_struct_train)\n",
    "y_struct_pred = lin_reg_struct.predict(X_struct_test)\n",
    "struct_mae = mean_squared_error(y_true=y_struct_test, y_pred=y_struct_pred) \n",
    "struct_mse = mean_absolute_error(y_true=y_struct_test, y_pred=y_struct_pred)\n",
    "struct_r2 = r2_score(y_true=y_struct_test, y_pred=y_struct_pred)\n",
    "\n",
    "lin_reg_unstruct = LinearRegression().fit(X_unstruct_train, y_unstruct_train)\n",
    "y_unstruct_pred = lin_reg_unstruct.predict(X_unstruct_test)\n",
    "unstruct_mae = mean_squared_error(y_true=y_unstruct_test, y_pred=y_unstruct_pred) \n",
    "unstruct_mse = mean_absolute_error(y_true=y_unstruct_test, y_pred=y_unstruct_pred)\n",
    "unstruct_r2 = r2_score(y_true=y_unstruct_test, y_pred=y_unstruct_pred)\n",
    "\n",
    "lin_reg_hybrid = LinearRegression().fit(X_hybrid_train, y_hybrid_train)\n",
    "y_hybrid_pred = lin_reg_hybrid.predict(X_hybrid_test)\n",
    "hybrid_mae = mean_squared_error(y_true=y_hybrid_test, y_pred=y_hybrid_pred) \n",
    "hybrid_mse = mean_absolute_error(y_true=y_struct_test, y_pred=y_hybrid_pred)\n",
    "hybrid_r2 = r2_score(y_true=y_hybrid_test, y_pred=y_hybrid_pred)\n",
    "\n",
    "print('Linear Regression...')\n",
    "print('Structured: MAE = {}, MSE = {}, R2 Score = {}'.format(round(struct_mae, 5), round(struct_mse, 5), round(struct_r2, 5)))\n",
    "print('Unstructured: MAE = {}, MSE = {}, R2 Score = {}'.format(round(unstruct_mae, 5), round(unstruct_mse, 5), round(unstruct_r2, 5)))\n",
    "print('Hybrid: MAE = {}, MSE = {}, R2 Score = {}'.format(round(hybrid_mae, 5), round(hybrid_mse, 5), round(hybrid_r2, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regression (SVR)...\n",
      "Structured: MAE = 0.00496, MSE = 0.05358, R2 Score = 0.38333\n",
      "Unstructured: MAE = 0.00844, MSE = 0.06811, R2 Score = -0.04837\n",
      "Hybrid: MAE = 0.00499, MSE = 0.05371, R2 Score = 0.37994\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Regression (SVR)...\n",
    "svr_struct = SVR().fit(X_struct_train, y_struct_train)\n",
    "y_struct_pred = svr_struct.predict(X_struct_test)\n",
    "struct_mae = mean_squared_error(y_true=y_struct_test, y_pred=y_struct_pred) \n",
    "struct_mse = mean_absolute_error(y_true=y_struct_test, y_pred=y_struct_pred)\n",
    "struct_r2 = r2_score(y_true=y_struct_test, y_pred=y_struct_pred)\n",
    "\n",
    "svr_unstruct = SVR().fit(X_unstruct_train, y_unstruct_train)\n",
    "y_unstruct_pred = svr_unstruct.predict(X_unstruct_test)\n",
    "unstruct_mae = mean_squared_error(y_true=y_unstruct_test, y_pred=y_unstruct_pred) \n",
    "unstruct_mse = mean_absolute_error(y_true=y_unstruct_test, y_pred=y_unstruct_pred)\n",
    "unstruct_r2 = r2_score(y_true=y_unstruct_test, y_pred=y_unstruct_pred)\n",
    "\n",
    "svr_hybrid = SVR().fit(X_hybrid_train, y_hybrid_train)\n",
    "y_hybrid_pred = svr_hybrid.predict(X_hybrid_test)\n",
    "hybrid_mae = mean_squared_error(y_true=y_hybrid_test, y_pred=y_hybrid_pred) \n",
    "hybrid_mse = mean_absolute_error(y_true=y_struct_test, y_pred=y_hybrid_pred)\n",
    "hybrid_r2 = r2_score(y_true=y_hybrid_test, y_pred=y_hybrid_pred)\n",
    "\n",
    "print('Support Vector Regression (SVR)...')\n",
    "print('Structured: MAE = {}, MSE = {}, R2 Score = {}'.format(round(struct_mae, 5), round(struct_mse, 5), round(struct_r2, 5)))\n",
    "print('Unstructured: MAE = {}, MSE = {}, R2 Score = {}'.format(round(unstruct_mae, 5), round(unstruct_mse, 5), round(unstruct_r2, 5)))\n",
    "print('Hybrid: MAE = {}, MSE = {}, R2 Score = {}'.format(round(hybrid_mae, 5), round(hybrid_mse, 5), round(hybrid_r2, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Layer Perceptron (MLP) Regression...\n",
      "Structured: MAE = 0.00473, MSE = 0.04971, R2 Score = 0.41259\n",
      "Unstructured: MAE = 0.00803, MSE = 0.06596, R2 Score = 0.00233\n",
      "Hybrid: MAE = 0.00499, MSE = 0.05327, R2 Score = 0.38031\n"
     ]
    }
   ],
   "source": [
    "# Multi-Layer Perceptron (MLP)...\n",
    "mlp_struct = MLPRegressor().fit(X_struct_train, y_struct_train)\n",
    "y_struct_pred = mlp_struct.predict(X_struct_test)\n",
    "struct_mae = mean_squared_error(y_true=y_struct_test, y_pred=y_struct_pred) \n",
    "struct_mse = mean_absolute_error(y_true=y_struct_test, y_pred=y_struct_pred)\n",
    "struct_r2 = r2_score(y_true=y_struct_test, y_pred=y_struct_pred)\n",
    "\n",
    "mlp_unstruct = MLPRegressor().fit(X_unstruct_train, y_unstruct_train)\n",
    "y_unstruct_pred = mlp_unstruct.predict(X_unstruct_test)\n",
    "unstruct_mae = mean_squared_error(y_true=y_unstruct_test, y_pred=y_unstruct_pred) \n",
    "unstruct_mse = mean_absolute_error(y_true=y_unstruct_test, y_pred=y_unstruct_pred)\n",
    "unstruct_r2 = r2_score(y_true=y_unstruct_test, y_pred=y_unstruct_pred)\n",
    "\n",
    "mlp_hybrid = MLPRegressor().fit(X_hybrid_train, y_hybrid_train)\n",
    "y_hybrid_pred = mlp_hybrid.predict(X_hybrid_test)\n",
    "hybrid_mae = mean_squared_error(y_true=y_hybrid_test, y_pred=y_hybrid_pred) \n",
    "hybrid_mse = mean_absolute_error(y_true=y_struct_test, y_pred=y_hybrid_pred)\n",
    "hybrid_r2 = r2_score(y_true=y_hybrid_test, y_pred=y_hybrid_pred)\n",
    "\n",
    "print('Multi-Layer Perceptron (MLP) Regression...')\n",
    "print('Structured: MAE = {}, MSE = {}, R2 Score = {}'.format(round(struct_mae, 5), round(struct_mse, 5), round(struct_r2, 5)))\n",
    "print('Unstructured: MAE = {}, MSE = {}, R2 Score = {}'.format(round(unstruct_mae, 5), round(unstruct_mse, 5), round(unstruct_r2, 5)))\n",
    "print('Hybrid: MAE = {}, MSE = {}, R2 Score = {}'.format(round(hybrid_mae, 5), round(hybrid_mse, 5), round(hybrid_r2, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Process Regression...\n",
      "Structured: MAE = 0.12942, MSE = 0.20384, R2 Score = -15.08494\n",
      "Unstructured: MAE = 19.56933, MSE = 1.58762, R2 Score = -2431.11164\n",
      "Hybrid: MAE = 0.00567, MSE = 0.05642, R2 Score = 0.29515\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Process Regression...\n",
    "gauss_struct = GaussianProcessRegressor().fit(X_struct_train, y_struct_train)\n",
    "y_struct_pred = gauss_struct.predict(X_struct_test)\n",
    "struct_mae = mean_squared_error(y_true=y_struct_test, y_pred=y_struct_pred) \n",
    "struct_mse = mean_absolute_error(y_true=y_struct_test, y_pred=y_struct_pred)\n",
    "struct_r2 = r2_score(y_true=y_struct_test, y_pred=y_struct_pred)\n",
    "\n",
    "gauss_unstruct = GaussianProcessRegressor().fit(X_unstruct_train, y_unstruct_train)\n",
    "y_unstruct_pred = gauss_unstruct.predict(X_unstruct_test)\n",
    "unstruct_mae = mean_squared_error(y_true=y_unstruct_test, y_pred=y_unstruct_pred) \n",
    "unstruct_mse = mean_absolute_error(y_true=y_unstruct_test, y_pred=y_unstruct_pred)\n",
    "unstruct_r2 = r2_score(y_true=y_unstruct_test, y_pred=y_unstruct_pred)\n",
    "\n",
    "gauss_hybrid = GaussianProcessRegressor().fit(X_hybrid_train, y_hybrid_train)\n",
    "y_hybrid_pred = gauss_hybrid.predict(X_hybrid_test)\n",
    "hybrid_mae = mean_squared_error(y_true=y_hybrid_test, y_pred=y_hybrid_pred) \n",
    "hybrid_mse = mean_absolute_error(y_true=y_struct_test, y_pred=y_hybrid_pred)\n",
    "hybrid_r2 = r2_score(y_true=y_hybrid_test, y_pred=y_hybrid_pred)\n",
    "\n",
    "print('Gaussian Process Regression...')\n",
    "print('Structured: MAE = {}, MSE = {}, R2 Score = {}'.format(round(struct_mae, 5), round(struct_mse, 5), round(struct_r2, 5)))\n",
    "print('Unstructured: MAE = {}, MSE = {}, R2 Score = {}'.format(round(unstruct_mae, 5), round(unstruct_mse, 5), round(unstruct_r2, 5)))\n",
    "print('Hybrid: MAE = {}, MSE = {}, R2 Score = {}'.format(round(hybrid_mae, 5), round(hybrid_mse, 5), round(hybrid_r2, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression...\n",
      "Structured: MAE = 0.00862, MSE = 0.06398, R2 Score = -0.0715\n",
      "Unstructured: MAE = 0.01823, MSE = 0.098, R2 Score = -1.2653\n",
      "Hybrid: MAE = 0.0089, MSE = 0.06612, R2 Score = -0.10659\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regression...\n",
    "dt_struct = DecisionTreeRegressor().fit(X_struct_train, y_struct_train)\n",
    "y_struct_pred = dt_struct.predict(X_struct_test)\n",
    "struct_mae = mean_squared_error(y_true=y_struct_test, y_pred=y_struct_pred) \n",
    "struct_mse = mean_absolute_error(y_true=y_struct_test, y_pred=y_struct_pred)\n",
    "struct_r2 = r2_score(y_true=y_struct_test, y_pred=y_struct_pred)\n",
    "\n",
    "dt_unstruct = DecisionTreeRegressor().fit(X_unstruct_train, y_unstruct_train)\n",
    "y_unstruct_pred = dt_unstruct.predict(X_unstruct_test)\n",
    "unstruct_mae = mean_squared_error(y_true=y_unstruct_test, y_pred=y_unstruct_pred) \n",
    "unstruct_mse = mean_absolute_error(y_true=y_unstruct_test, y_pred=y_unstruct_pred)\n",
    "unstruct_r2 = r2_score(y_true=y_unstruct_test, y_pred=y_unstruct_pred)\n",
    "\n",
    "dt_hybrid = DecisionTreeRegressor().fit(X_hybrid_train, y_hybrid_train)\n",
    "y_hybrid_pred = dt_hybrid.predict(X_hybrid_test)\n",
    "hybrid_mae = mean_squared_error(y_true=y_hybrid_test, y_pred=y_hybrid_pred) \n",
    "hybrid_mse = mean_absolute_error(y_true=y_struct_test, y_pred=y_hybrid_pred)\n",
    "hybrid_r2 = r2_score(y_true=y_hybrid_test, y_pred=y_hybrid_pred)\n",
    "\n",
    "print('Decision Tree Regression...')\n",
    "print('Structured: MAE = {}, MSE = {}, R2 Score = {}'.format(round(struct_mae, 5), round(struct_mse, 5), round(struct_r2, 5)))\n",
    "print('Unstructured: MAE = {}, MSE = {}, R2 Score = {}'.format(round(unstruct_mae, 5), round(unstruct_mse, 5), round(unstruct_r2, 5)))\n",
    "print('Hybrid: MAE = {}, MSE = {}, R2 Score = {}'.format(round(hybrid_mae, 5), round(hybrid_mse, 5), round(hybrid_r2, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression...\n",
      "Structured: MAE = 0.00391, MSE = 0.04531, R2 Score = 0.51353\n",
      "Unstructured: MAE = 0.00834, MSE = 0.06686, R2 Score = -0.03603\n",
      "Hybrid: MAE = 0.00397, MSE = 0.04541, R2 Score = 0.50676\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regression...\n",
    "rf_struct = RandomForestRegressor().fit(X_struct_train, y_struct_train)\n",
    "y_struct_pred = rf_struct.predict(X_struct_test)\n",
    "struct_mae = mean_squared_error(y_true=y_struct_test, y_pred=y_struct_pred) \n",
    "struct_mse = mean_absolute_error(y_true=y_struct_test, y_pred=y_struct_pred)\n",
    "struct_r2 = r2_score(y_true=y_struct_test, y_pred=y_struct_pred)\n",
    "\n",
    "rf_unstruct = RandomForestRegressor().fit(X_unstruct_train, y_unstruct_train)\n",
    "y_unstruct_pred = rf_unstruct.predict(X_unstruct_test)\n",
    "unstruct_mae = mean_squared_error(y_true=y_unstruct_test, y_pred=y_unstruct_pred) \n",
    "unstruct_mse = mean_absolute_error(y_true=y_unstruct_test, y_pred=y_unstruct_pred)\n",
    "unstruct_r2 = r2_score(y_true=y_unstruct_test, y_pred=y_unstruct_pred)\n",
    "\n",
    "rf_hybrid = RandomForestRegressor().fit(X_hybrid_train, y_hybrid_train)\n",
    "y_hybrid_pred = rf_hybrid.predict(X_hybrid_test)\n",
    "hybrid_mae = mean_squared_error(y_true=y_hybrid_test, y_pred=y_hybrid_pred) \n",
    "hybrid_mse = mean_absolute_error(y_true=y_struct_test, y_pred=y_hybrid_pred)\n",
    "hybrid_r2 = r2_score(y_true=y_hybrid_test, y_pred=y_hybrid_pred)\n",
    "\n",
    "print('Random Forest Regression...')\n",
    "print('Structured: MAE = {}, MSE = {}, R2 Score = {}'.format(round(struct_mae, 5), round(struct_mse, 5), round(struct_r2, 5)))\n",
    "print('Unstructured: MAE = {}, MSE = {}, R2 Score = {}'.format(round(unstruct_mae, 5), round(unstruct_mse, 5), round(unstruct_r2, 5)))\n",
    "print('Hybrid: MAE = {}, MSE = {}, R2 Score = {}'.format(round(hybrid_mae, 5), round(hybrid_mse, 5), round(hybrid_r2, 5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
